## Exercise 2 - part 1

To accomplish the first part, you need to run `script.sh`, provided you have made it executable with `chmod +x script.sh`. If the matrix size is smaller than 10, you will see it printed on the stdout, while for larger matrices a file `distributed_matrix.dat` will be created. The number of processes can be changed from within the bash script.

The program `distributed_blocking.c` initializes a distributed matrix of dimension (N,N), by striping it over the outer index, being the row index for a C-ordered matrix (of course, the reason is better memory access pattern). In the case the size of the matrix is not a multiple of the number of processes, we need to take care of the remainder, and this is done increasing of one the local dimension for all the processes such that their rank is smaller than the rest. As we have seen in lecture, this is an easy way to avoid load unbalancing. Subsequently, we need to print/write the matrix. In the absence of a parallel file system, the best and only feasible way to do so is to send and enqueue all the distributed portions on the root process, which will process them sequentially. In this program, the task is accomplished by making use of the blocking `MPI_Send` and `MPI_Recv` routines. Notice that we need to forward also the number of rows for each sub-matrix, since we have taken care of the rest. While printing is a trivial feat, writing on a binary file is made possible by a bunch of functions defined in `stdlib.h`.
